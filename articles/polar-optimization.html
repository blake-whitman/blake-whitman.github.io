<!DOCTYPE html>
<html>
  <head>
    <link rel="icon" type="image/x-icon" href="/logo.ico">
    <link rel="stylesheet" href="../static/css/style.css">
    <link href="../static/css/code.css" rel="stylesheet" type="text/css">
    <title>Optimization over polar convex sets and graphical methods - Blake Whitman</title>
  </head>
  <body>
<span class="breadcrumb"><a href="../index.html">Home</a> &gt; <a href="https://blake-whitman.github.io/#articles">Articles</a> &gt; Optimization over polar convex sets and graphical methods</span>
<h1>Optimization over polar convex sets and graphical methods</h1>
<p><strong>Abstract</strong> The problem of optimizing certain polar convex regions has been a topic left unaddressed for many years. Recently, many beautiful results have been obtained related to prepositions invoked in conceptual spaces. Problems currently under investigation include verifying whether the notion of polar convexity extends to plural landmarks (see Mador-Haim and Winter, 2015).</p>
<p>Based on the work of Zwarts and Gardenfors (Journal of Logic, Language and Information. 25, 109–138, 2016), we introduce and study optimization problems over polar convex regions and propose solutions by graphical methods. Through an interpretation of the graphical method of linear optimization, we apply this method to that of polar convex regions.</p>
<h2>Introduction</h2>
<p>In this paper, we address the problem of polar convexity in optimization. The focus is particularly on polarizing the graphical method from its linear applications. We further discuss whether polar convexity is a necessary condition for polar optimization to remain feasible. Our results generalize previous studies that conclude certain regions are polar convex when analyzing polar coordinates as opposed to Cartesian coordinates (Zwarts and Gardenfors). In the next section, an overview of the classical graphical method for linear optimization is provided. Through graphed examples, we show the process of solving a maximization problem in this manner. Section 3 goes in depth regarding polar convexity and its various properties. Several key traits are defined in this section and subsequently utilized in Section 4. In Section 4, we introduce optimization problems over these previously introduced polar convex regions by illustrating solutions to the graphical method. We then introduce similar optimization problems that incorporate more complex figures. These figures may not necessarily prove to be solvable using the linear method of optimization, and as such require the newly introduced graphical method. The mentioned solutions involve polarizing the method of polarly linear optimization and polarizing interior-point methods for otherwise nonlinear optimization problems. Lastly, we conclude our thoughts on the findings discussed, as well as examine opportunities for future work. See the Appendix for subject material related to the main ideas prevailing in this paper.</p>
<h2>Graphical method for linear optimization</h2>
<p>We will now discuss the graphical method for linear optimization before exploring its further applications to polar convex optimization. The treatment here further generalizes that of Reeb and Leavengood; see [3] for more details. <em>Linear optimization</em> refers to the method of extracting one or more best outcomes from linear relationships. The optimized outcome is in general a maximization or minimization of the given linear representation. These representations possess certain limitations that inhibit their ability to reach values above or below specified thresholds. This event is also referred to as the <em>constraint set</em>, and it is what enacts linear programming; it is necessary to consider ongoing constraints in order to optimize results. A lower bound of zero is observed by default for all variables in the constraint set, thus avoiding negative resources. Linear inequalities are utilized to express the allotment of resources for each constraint. To maximize or minimize a linear function requires a predetermined <em>objective function</em>. Linear optimization maintains that an objective function can possess only first degree polynomial terms, such as 400x or 77y. The technique seeks to solve problems involving lines or planes with a constraint set of linearly related equations.</p>
<p>Linear optimization problems in general are expressed in terms of matrix form. There are multiple differing representations for linear programming, each with their own unique benefit. We will take a look at the methods relevant to our study here. Consider first the following representation, such that <em>c</em>, <em>A</em>, and <em>b</em> are matrices, <em>x</em> is the unknown variable involved in the constraint set and objective function, and each value is real and continuous:</p>
<p><img src="/static/img/optimization/Eq-1.png"></p>
<p>This generalization can be referred to as the <em>standard form</em>. Values c, b, and x are to be viewed conceptually as column vectors, while A is an m x n matrix such that the element in row i, column j is Aij. In addition, cTx denotes the transpose of the c vector, in terms of its usual definition. Notice too that the value of x is non-negative. This holds true for all values considered in the standard form, since we seek to avoid the expression of negative resources. Moreover, the optimization type is a maximization, which remains the case in all standard form examples. To be a viable representation of standard form, a linear program must be a maximization problem involving strictly non-negative variables, where only equality statements are utilized to express relationships between variables. We can further express problems involving minimization or linear inequalities in terms of maximization and thus the standard form. In fact, all linear optimization problems can be adjusted and formatted into the standard form.</p>
<p><strong>Example 2.1</strong> Consider example 2.1, where we take a collection of linear inequality constraints and turn them into statements of equality. In doing so, the given minimization problem is manipulated into an eligible standard form maximization problem. As before, x1, x2, and x3 are real, continuous values such that the following quantities hold true.</p>
<p><img src="/static/img/optimization/eq-2.png"></p>
<p>To organize this into the standard form, we must alter the linear inequalities beneath the objective function into respective statements of equality. We also have to express the linear program in terms of a maximization as opposed to the current minimization approach. This can be achieved by applying the algorithm max = -min, which entails taking the opposite of each element of the objective function. Let z = 4x1 +5x2 -x3. Then,max=z’suchthatz’=-z. Hence,z’=−4x1 -5x2 +x3. Next,werearrangethe inequality constraints into statements of equality. This is made possible by introducing either a slack or surplus variable. A <em>slack</em> variable is a non-negative real valued variable used in the less than or equal to case. It is added onto the remaining variables in the inequality. In an analogous way, a <em>surplus</em> variable is a non-negative real valued variable used in the greater than or equal to case. It is subtracted off of the remaining variables in the inequality. In example 2, it is evident that we need a surplus variable in the line −x1 + x2 + 4x3 ≥ 18, and we also need a slack variable in the line −2x1 + 3x2 + x3 ≤ 5. Let x4 and x5 represent decision variables, such that x4 is a slack variable and x5 is a surplus variable. Then, the new linear equality statements are as follows: −x1 + x2 + 4x3 - x5 = 18 and −2x1 + 3x2 + x3 + x4 = 5. x1 + 7x2 - 2x3 = 1 remains unchanged, since it already possesses the desired equals sign. As such, the following representation is logically equivalent to Example 2.1:
<p><img src="/static/img/optimization/Eq-3.png"></p>
<p>Another form worth noting is <em>canonical form</em>. It follows a similar structure to standard form linear programs, with a certain key difference. The canonical form is able to be expressed in terms of a linear inequality constraint, while the standard form requires the constraint set to involve strictly statements of equality. The two forms are similar, though, in that both require non-negativity among decision variables, along with containing objective functions that maximize parameters. Here is the canonical form of a linear optimization problem:</p>
<p><img src="/static/img/optimization/Eq-4.png"></p>
<p>To convert from one form to the other requires a transformation using matrices and column vectors. In order to go from standard form to canonical form, one must replace A and b in Ax = b, such that the new representation is Ax ≤ b. In canonical form, A is of the matrix form: [A −A]. Similarly, b is of the column vector form as follows: [-b b].</p>
<p>Next, we will take a look at the process of graphically solving a linear optimization problem. We have already observed the first step, which is to translate an appropriate problem into its resulting objective function and list of constraint inequalities. We now show the remaining process for solving problems involving linear programming.</p>
<p><strong>Example 2.2</strong> Consider the following example, 2.2, which illustrates a maximization problem involving two constraint inequalities. All values are restricted to be non-negative. Note that since there are only two variables, we can solve this problem graphically in two dimensions. If there exists n variables, such that n ≥ 1, then the resulting graphed solution must be in n dimensions.</p>
<p><img src="/static/img/optimization/ineq-image.png"></p>
<p>To plot the graph, we begin by rewriting the two constraint inequalities as statements of equality. Then, solve each equation for its x and y intercepts.</p>
<p><img src="/static/img/optimization/equal-image.png"></p>
<p>Hence, we have the following x-intercepts: (14, 0), (24, 0) and y-intercepts: (0, 21), (0, 15). We now plot the two lines in Figure 1 below containing intercepts from their corresponding constraint equations.</p>
<p><img src="/static/img/optimization/graph-unshade.png"></p>
<p>Upon displaying the two constraint lines, we then need to verify the valid side of each one. To do this, consider an example point such as the origin, (0,0), and substitute it into each constraint equation. Since 15(0) + 10(0) ≤ 210 and 5(0) + 8(0) ≤ 120, the side of each constraint line facing the origin represents the valid region. Each valid side is shaded gray below in Figure 2, with the one from 15x + 10y ≤ 210 highlighted in red and the one from 5x + 8y ≤ 120 highlighted in blue. The purpose of this step is to allow for a seamless location of the <em>feasible region</em>. The feasible region is the area in which the intersection of both valid sides lies. Any point that dwells outside of the valid region of a constraint line is infeasible. The feasible region is limited to strictly positive values in quadrant I due to the non-negative conditions imposed on the input variables. Below, the feasible region has been shaded in Figure 3. Notice how it ignores the portions of the previous graph that extend beyond the validity of 5x + 8y ≤ 120.</p>
<p><img src="/static/img/optimization/graph-shade1.png"></p>
<p>We have now established the feasible region, which means that the optimal solutions lies somewhere within the shaded region. We must determine where that point is, though, by observing the <em>direction of improvement</em>. The direction of improvement is meant to illustrate which way is trending toward optimization. For instance, the origin could be optimal, in which case the direction of improvement would be toward (0, 0). Alternatively, the direction could be pointed away from the origin to some undetermined point of intersection. Consider the following example in which we further display this concept. To do so, let <em>z</em> be equal to two arbitrary values, z = 24 and z= 18. We will then plot two objective function lines in order to verify which direction causeszto increase toward maximization. Follow the same steps as before to isolate the x and y intercepts as follows:</p>
<p><img src="/static/img/optimization/more-eqs.png"></p>
<p>Now observe these two lines plotted with their respective intercepts alongside the previous feasible region graph we ascertained. The direction of improvement lines are displayed in the Figure 4 below. As the plotted lines move away from the origin, the value of z increases, since the blue line corresponds to z = 24 and the red line corresponds to z = 18. Hence, we can conclude that the maximum value of <em>z</em> lies in the direction away from the origin. The exact maximum value of the optimization problem occurs at the point furthest away from the origin, whilst still maintaining a presence in the feasible region. That point has been bolded in Figure 5. Notice that it dwells at the intersection of the two constraint equations.</p>
<p><img src="/static/img/optimization/graph-shade2.png"></p>
<p>Now that the maximization point has been spotted, we can solve for it by setting up a system of two equations. The solution (x,y) will then represent the maximal output given the constraints.</p>
<p><img src="/static/img/optimization/ans-image.png"></p>
<p>Hence, the optimal solution is at (48/7, 75/7). To determine the maximum z value for the objective function, we input x = 48/7 and y = 75/7 into z = 2x + 3y. Therefore, z = 2(48/7) + 3(75/7) = 7. We can conclude that the maximum value of z, given the two constraint inequalities, is 321/7.</p>
<p>There are several other constraint types that pertain to various linear programming problems. One is known as the <em>mixture constraint</em>, and it occurs when a constraint equation passes through the origin (0,0). Another way to conceptualize mixture constraints is to think of one quantity being limited to a certain frequency based on another quantity. Two or more variables are strictly related amid this constraint type.</p>
<p>An alternative constraint type is the <em>equality constraint</em>. This type of constraint is analagous to the mixture constraint, except it combines two or more variables alongside coefficients to form a statement of equality. This leads to the removal of a valid side, as we expressed before, and instead allows for solutions that lie strictly on its line.</p>
<p>At other times, we may experience optimization problems with multiple optimal solutions. This occurs when the problem includes a larger assortment of constraint inequalities instead of two. There are then more possible maximization points in the feasible region, which each correspond to a specific z output. The largest z value represents the maximum solution, and z is not limited to one point. For instance, if two points in the feasible region each correlate with the same maximum output value, then that optimization problem contains two unique solutions.</p>
<p>Unbounded solutions also come into consideration in some applications. These occur when one is provided with an unlimited allotment of resources, and the challenge is then to provide further constraints that may have been overlooked. Without additional constraint inequalities, the linear programming problem will not make logical sense. For example, consider the constraint equation y = 10. If we were to graph that constraint on the above coordinate planes, it would originate from (0, 10) due to the non-negativity condition for x and y. The plotted line would then proceed to the right for an infinite length of time, and thus we could improve the solution infinitely by continually adding more of the y resource. Adding one or more subsequent constraints will allow us to pinpoint an exact solution that makes sense within the confines of linear optimization.</p>
    
    
    
    
    
    
    
    
    
<ol>
<li><strong>Overview</strong> In order to understand the different values used in this experiment, it may help to first be given a general overview of the setup. To begin with, there are a predetermined allotment of buses and bus stops, and the buses are tasked with revolving around the bus stops. Starting with the simplest case, let us assume there is 1 bus and n bus stops. Then, the bus will first visit bus stop 1, then bus stop 2, and continue onward until it reaches the nth bus stop. In other words, bus i will travel in order from stop 1, 2, . . . j, j ∈ Z. After that point, it will begin again at bus stop 1 and proceed with this pattern until the simulation resolves. This idea remains consistent independent of the number of buses in use. The only modification is that the buses will be evenly distributed to maximize their route efficiency. Maintaining an equivalent distance between buses is addressed in the "Variables" section below.</li>
<li><strong>Constants</strong> A myriad of constants were utilized amid the simulation process. These values were often approximated in order to simplify the testing process, and each can be altered as needed based on the particular bus system under surveillance. During testing, the following equivalencies were used:

<div class="highlight"><pre><span></span><span class="n">sim_const</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;num_buses&quot;</span><span class="p">:</span> <span class="mf">4</span><span class="p">,</span>
            <span class="s2">&quot;num_bus_stops&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
            <span class="s2">&quot;bus_capacity&quot;</span><span class="p">:</span> <span class="mf">40</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">]</span>
<span class="p">)</span></div>
The simplifying assumption was made that each bus stop is an equidistant length from both the preceding and subsequent bus stop. To account for this, the metric bus stop interval can be defined as the time it takes for a bus to go from stop i -> stop i+1. For these trials, that length of time is 20 minutes. Thus, bus 1 will first reach bus stop 1 in 20 minutes, and it will again reach bus stop 1 at a time of 120 minutes in our simulation. Or, for an all encompassing solution, consider the following theorem:
<blockquote>
<p><strong>Theorem 2.1</strong> Bus i will reach stop j in n minutes, and bus i returns to stop j again in [(numStops * bus stop interval) + n] minutes.</p>
</blockquote>
</li>
<li><strong>Variables</strong> Not all values used were constants, so now we will provide insight into the various components of the program that were repeatedly updated using some form of randomness. In an effort to compare trials of multiple lengths, duration of simulation was varied. The original experiment length was set to 1,440 minutes (1 day), but longer trials were incorporated as well. We hypothesize that with more runtime, we will encounter a closer approximation to a Poisson Process. By altering the trial lengths, this idea will be closely monitored. Another value that fluctuates throughout the trials is the number of passengers departing each bus. The number departing depends entirely on which stop the bus encounters, as well as the total number of passengers on the bus upon arrival. The relative usage of the bus stop in the system will lead to variant departure rates. For instance, the Recreation and Physical Activity Center (RPAC) at Ohio State is a well visited destination, and as such, warrants a higher rate of disembarking passengers than St. John Arena. This thought is taken into account when determining passenger exchanges at each bus stop. As previously mentioned in the "Overview," the distance between buses must remain the same for all buses involved. Thus, a new term, bus distance interval, is defined as the allotted space between two buses. It can be calculated with the following theorem:
<blockquote>
<p><strong>Theorem 2.2</strong> bus distance interval = (bus stop interval * numStops) / numBuses</p>
</blockquote>
In our experiment, this value was computed to be 25 minutes, which means each bus is initially sent off 25 minutes after the one in front of it until all buses are running. The gap between buses will then perpetually remain 25 minutes until the end of the trials. With a greater or lesser number of buses or stops, this metric will change. Its aim is to distribute bus inventory evenly throughout the entirety of the system. To properly address the randomness aspect of a Poisson Process, we had to ensure that consumers arrived at bus stops randomly throughout the simulation. To achieve this, each bus stop was assigned a random digit between [arriveLow, arriveHigh]. Both arriveLow and arriveHigh are integer values, in minutes, that the random digit falls between, inclusively. These numbers were again based on the usage rate of each bus stop in consideration, with more densely populated bus stops having lower arriveLow and arriveHigh numbers. Lower values indicate a passenger arriving in fewer minutes, on average, than corresponding higher values. Expected Rate of Arrival (eROA) represents the mean value of arriveLow and arriveHigh. As eROA increases, the flow of arriving passengers will decrease. Here are the figures used for our five bus stops, to provide a clearer insight into the range considered for each arriving passenger:
<p><img src="/static/img/table-4.png"></p>  
As mentioned previously, a lower expected ROA points toward a highly traversed bus stop, so we can conclude that the RPAC was pinpointed as the single most visited stop out of the five routes. Conversely, Knowlton Hall and the Student Union experience more infrequent customer arrivals. As we move forward, we can compare the wait times of these two unique situations to see the impact, if any, on their respective wait time distributions.
</li>
<li><strong>Data Structures</strong> The main data storage tools used were Arrays, ArrayLists, and Queues. Each serve a distinct purpose in the initialization, storage, and output of values for each customer in the simulation. Arrays are structures that contain a finite set of elements and do not change in length. Two prominent examples from this program include the aˆtimeWaitingaˆ and aˆnumWaitingaˆ Arrays. These serve to track the total number of passengers that wait at each stop throughout the simulation, along with the total time each respective passenger waited. The totals from each bus stop are then used to compile the average wait time for every person in each individual line. Additionally, the "passengers" and "waiting" Arrays were created to track the flow of passengers on bus numBuses and at bus stop numStops, respectively. Each element in those two Arrays is initialized with 0 before eventual updates during the iterative process of the simulation. Alternatively, Queues utilize FIFO (first in, first out) implementation to store objects of the same type. For our purposes, these Queues will store integer values. FIFO indicates that the value inserted into the Queue first will be the first value taken out of the Queue, regardless of the amount of additional integers added to the Queue before output. This implementation is useful for tracking data such as waiting times, which is its main usage in this simulation. We utilize an Array of Queues entitled "allQueues" that follows the arrival and dispersal of passengers in line at each bus stop. In doing so, the Queues in each element of the Array contain the arrival times of each passenger up until the moment that passenger boards a bus. This process will be explained further in the loop body section, as this structure was vital in computing wait times for the subsequent final distribution. ArrayLists are similar to Arrays, except for the fact that their set of elements can be altered in length at any point in time. Therefore, these structures are heavily utilized when dealing with values that are not constants, such as total passenger wait times in this experiment. It is unclear how many passengers will wait in each line during a given trial. Therefore, we use the ArrayList "allTimes" to continually store each new waiting time before eventually outputting and plotting the accumulated distribution.</li>
<li><strong>Main Program Structure</strong> In order to understand the entirety of the program, it is simpler to think in terms of its individual components. In this section, we will layout the structure of the simulation and explain the methodology behind each section. Below, P(a) will represent the arrival of a new customer at a bus stop, while B(a) illustrates a bus reaching a bus stop. The gist of the program is to check for the occurrences of these two events, while updating overarching results accordingly. Here is the simplified explanation of the iterative process used to simulate the bus system, broken down into several parts:
  <ul>
    <li><strong>Outermost Loop</strong> This portion makes the most intuitive sense. The loop reads:
    <div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">bus_interaction_sim</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">sim_length</span><span class="p">):</span>
    <span class="n">while</span> <span class="o">time</span> <span class="n"><=</span> <span class="o">sim_length</span><span class="n">:</span>
    <span class="p">    ...</span>
    <span class="p">    time</span><span class="n">+</span><span class="p">=</span> <span class="n">1</span>
</pre></div>
    Therefore, the program will continue to run until the time value, which is incremented by 1 minute each iteration, reaches the predetermined concluding length of the simulation. The remaining sections of code below are each enclosed in this outermost loop.
    </li>
    <li><strong>Checks for P(a) and updates values</strong> First, let us take a look at the loop code for P(a):
    <div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">pa_transition</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">time_per_arrival</span><span class="p">,</span> <span class="n">num_stops</span><span class="p">):</span>
    <span class="n">for</span> <span class="o">count</span> <span class="n">in</span> <span class="o">range(num_stops)</span><span class="n">:</span>
    <span class="p">    if</span> <span class="o">time</span> <span class="n">%</span> <span class="o">time_per_arrival[count]</span> <span class="o">==</span> <span class="o">0</span><span class="n">:</span>
    <span class="p">       ...</span>
    <span class="c1">#  Randomize time_per_arrival[count] and queue passenger in line count</span>
    </pre></div>
    Essentially, the program iterates through each bus stop and checks to see whether a passenger arrives at a stop at that specific time or not. A passenger can arrive at any combination of bus stops, including each one, depending on the current time t and the computed arrival rates for each bus stop. We test whether the current time in the experiment is divisible by the arrival rate for the bus stop in consideration. If it is, then we add one passenger to the line, Queue up that passenger's time of arrival, and then calculate a new arrival rate to be used for that bus stop. The recalculated arrival rate will be utilized during future iterations, to ensure random arrival intervals. This process is repeated for the duration of the trials.
    </li>
    <li><strong>Checks for P(b) and updates values</strong> Next, we survey the code for P(b):
    <div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">pb_transition</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">time_per_bus</span><span class="p">,</span> <span class="n">distance_between</span><span class="p">,</span> <span class="n">iterator</span><span class="p">,</span> <span class="n">num_buses</span><span class="p">):</span>
    <span class="n">for</span> <span class="o">count</span> <span class="n">in</span> <span class="o">range(num_buses)</span><span class="n">:</span>
    <span class="p">    if</span> <span class="o">time</span> <span class="n">%</span> <span class="o">(iterator[count]</span> <span class="o">* time_per_bus)</span> <span class="o">+</span> <span class="o">count</span> <span class="o">* distance_between</span> <span class="o">==</span> <span class="o">0</span><span class="n">:</span>
    <span class="p">       ...</span>
    <span class="c1">#  compute the number of passengers that depart the bus at stop "count" and update the corresponding number of passengers left on the bus</span>
    </pre></div>
    The idea behind this code is to cycle through the system of buses, while checking to see one by one whether a bus reaches a bus stop. If the second line of code equates to 0, as specified, then we will know that bus number COUNT will have arrived at a bus stop. Arrays contain indexing that commences from 0, which means bus 1 equates to a count value of 0, bus 2 = count 1, ... , bus i = count i − 1. The bus stop number is then determined with another segment of code. We can make the assumption that the bus stop is equivalent to the value of iterator[count] up until the moment iterator[count] exceeds the number of bus stops. Once iterator[count] > numStops, it will no longer make logical sense for that value to be used. As an example, a bus stopping at bus stop 6, given that there are only 5 bus stops, is not a possible outcome. Therefore, we update the value to account for this result.
Using the new value, we can now assert that bus COUNT has reached bus stop STOP. We then compute the number of passengers that depart the bus at STOP and update the corresponding number of passengers left over on the bus, before arriving at one more tree of outcomes. There are two scenarios that take place when a bus reaches a stop:
    <ul>
      <li>There are more passengers waiting in line than the bus can account for, which leads to some passengers being forced to wait for the next bus. This can be thought of as <em>spillover</em>.
      </li>
      <li>The bus can accommodate each waiting passenger, and they all board the bus without issue.
      </li>
    </ul>
    The code we used to approach these two situations is explored below.  
    <div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">bus_stop_interaction</span><span class="p">(</span><span class="n">waiting</span><span class="p">,</span> <span class="n">passengers</span><span class="p">,</span> <span class="n">capacity</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">count</span><span class="p">):</span>
    <span class="n">if</span> <span class="o">waiting[stop]</span> <span class="n"><=</span> <span class="o">capacity - passengers[count]</span><span class="n">:</span>
    <span class="p">   while</span> <span class="o">waiting[stop]</span> <span class="n">></span> <span class="o">0</span><span class="n">:</span>
    <span class="p">      ...</span>
    <span class="p">else:</span>
    <span class="p">   ...</span>
    <span class="p">   while</span> <span class="o">passengers[count]</span> <span class="n">!=</span> <span class="o">capacity</span><span class="n">:</span>
    <span class="p">      ...</span>
    </pre></div>
    The first IF statement determines whether the number of passengers waiting in line at <em>STOP</em> is less than or equal to the number of openings on the bus. If so, the program will enter the loop body and continue to update values until the amount left waiting is 0. If the number of waiting passengers is greater than the amount of openings, however, the program will iterate up until the bus is full. In each case, a variety of computations are performed to update the total number of passengers waiting at each stop, the total time waited at each stop, the wait times of each individual passenger, and the current number of passengers both waiting in line and on board a bus.
    </li>
    </ul>
    <li><strong>Poisson Distribution</strong>
    The previous sections display the empirical side of Queuing Theory application. Now, we take a look at the theoretical aspect in order to test the ideal output of the experiment and compare it to our accrued data. For a Poisson Process, the probability of a passenger waiting a certain time t can be ascertained with multiple known quantities as follows:
    <blockquote>
    <p>t: Duration of time, in minutes, hours, days, etc</p>
    <p>λ: Expected waiting time</p>
    <p>x: Simulated waiting time</p>
    </blockquote>
    These values are either known as constants, or they are computed during the simulating process. λ is determined in the main loop body, and the values found are summarized below.
    <p><img src="/static/img/table-5.png"></p>  
    Time <em>t</em> is set to the duration of the experiment, which is 1 day in this instance. This parameter will be altered in Section III to view any potential distribution variation. Additionally, x represents each waiting time that is simulated, as opposed to expected. For instance, if the Student Union ends experimentation with waiting times of 2, 5, 9, 10, 11, 12, 12, 11, 1, 28, then each of those values will be utilized as values of x in the probability calculations. In other words, the calculation will be repeated for each waiting time x, while time (t) and expected waiting time (λ) remain unchanged for each stop. With these parameters, we can then apply the following theorem to calculate the expected probability of waiting times equating to x.
    <blockquote>
    <p>P(Arrivals = x) = e^(−λt(λt)) / (x!)</p>
    </blockquote>
    Applying this formula to a range of x values will provide us with a full picture of the distribution for each bus stop and the system overall. In this section, we layout the expected distribution of waiting times for each bus stop, along with the cumulative picture of all bus stops. These visualizations will then be used as a baseline for comparison to the simulated data in the ensuing section. The distributions are largely the same, as the only disparity between them lies in their respective I values.
As such, one would expect the corresponding simulated waiting times to be independent in regard to bus stop. We will view these hypothetical distributions in the next section to offer a vivid examination of the empirical evidence, before concluding with our overall findings and future relevant areas of study.
    </li>
</ol>
<h2>Visualization</h2>
<p>In this section, we initially view the simulated distribution of wait times. These graphs are pitted up against the theoretical output, seen above in part F of Section 2, to verify their validity. The section concludes with insight into additional circumstances that may lead to distribution changes, along with these altered distributions.</p>
<ul>
<li><strong>Empirical Wait Time Distribution</strong> The following data is retrieved from the "allTimes" ArrayList. The data structure "allTimes" tracks the wait times for passengers at each stop i, aˆ¦ , numStops, and outputs the data into an organized histogram. Below, the accumulated distributions for each bus stop, along with a cumulative result from all bus stops, are displayed. Wait times are shown in bins of minutes, with their respective frequencies listed along the vertical axis.
 <p><img src="/static/img/plot-4.png"></p>
 <p><img src="/static/img/plot-3.png"></p>
 <p><img src="/static/img/plot-5.png"></p>
 <p><img src="/static/img/plot-6.png"></p>
 <p><img src="/static/img/plot-7.png"></p>
 The data is acquired in a structurally randomized way, so the output is not meant to flawlessly replicate any specific distribution. In order to test its approximation to the Poisson Process, the empirical and theoretical values can be viewed simultaneously, which we provide in Table 3.
 <p><img src="/static/img/table-1.png"></p>
  Expected and Simulated values differ significantly in certain wait time intervals, while the approxima- tion is more accurate in others. This occurs due to the nature of the experiment, as well as the theory behind a Poisson Process. To begin with, take a look at another table that illustrates the bus movement at the onset of the experiment.
  <p><img src="/static/img/table-3.png"></p>
  A bus will arrive at each stop i, . . . , numStops at a perpetual time interval of 25 minutes given the proposed simulation parameters. Since these arrival times are consistently dispersed, along with customer arrivals being randomized, then the probability of a passenger waiting anywhere from 1 to 25 minutes is the same throughout. The simulated data reflects this knowledge, as the only data is relatively uniform in frequency from [0, 25] minutes. Wait times beyond 25 minutes represent spillover from one bus to the next, and cannot be predicted as accurately as those in the bus stop arrival range. A proposed solution to this issue is discussed in the closing thoughts, as well as several alterations that can be made to the existing program structure.</li>
  <li><strong>Exploring Spillover</strong> <em>Spillover</em> has been mentioned multiple times in this study, and in this subsection we revisit it directly. The term is defined as one or more passengers being unable to board a bus due to it reaching capacity, causing the displaced passengers to wait for the next bus able to accommodate them. To test the impact of spillover on wait time distributions, we increased the arrival rates of passengers, while also lengthening the time it takes bus i to go from stop j → stop j + 1. These alterations are meant to represent a bus system that transports more of the general populace than the COTA system does in Columbus. Spillover is subject to the environment in which the bus system finds itself, and will vary depending on the specific input parameters. This segment portrays one possible implementation, and the results from <em>All Bus Stops</em> are displayed underneath.
    <p><img src="/static/img/plot-1.png"></p>
     The distribution of times from [0, 25] remains largely unchanged. However, there is an evident increase in wait times in the interval immediately beyond 25 minutes and continuing until nearly 45 minutes elapse, equal to the span of (25, 45]. Longer wait times occur far less frequently, yet still more so than in the original data used earlier. Therefore, in more densely populated bus systems, it is fair to assert that the uniform distribution is extended beyond simply the bus distance interval. Additionally, an increasingly large proportion of wait times exist beyond one spillover bus arrival. In this case, the aforementioned longer wait times are greater than 50 minutes (2 * busDistanceInterval), and are far more prevalent than in the COTA replication.</li>
  <li><strong>Varying Simulation Duration</strong> We now revisit the idea of variable experiment lengths. The final distribution of times will hypothet- ically become more pronounced, regardless of which form it takes, as time t approaches infinity. In this subsection, we will increase the simulation length from 1 day to 1 week in an effort to verify the aforementioned hypothesis. The results are displayed below:
    <p><img src="/static/img/table-2.png"></p>
     The results reflect what we have uncovered in shorter trials: the vast majority of wait times fall within the range of [0, busDistanceInterval], along with a few spillover cases as well. Since we looked at the distribution of more populated systems as well, it may prove beneficial to study that same circumstance over the course of 1 week to compare to the COTA replica. 
    <p><img src="/static/img/plot-2.png"></p>
    Over the course of nearly 15,000 more waiting passengers, the uniform distribution extended beyond simply [0, busDistanceInterval] to approximately 0-45 minutes. Additionally, the frequency of pas- sengers waiting for more than one bus at a time increases also. Interestingly, though, there appear to be fewer lengthy wait times when compared to the COTA population data. This could suggest that while passengers may have to wait longer on average, densely populated bus systems are more well equipped to handle sudden upticks in transit demand than their more sparsely traveled counterparts.</li>
</ul>
<h2>Concluding Remarks</h2>
<p>This study introduces a hypothetical system of buses and bus stops, based on real life parallels. We then produce waiting times for a mass quantity of passengers before testing their corresponding distributions in relation to potential theoretical outcomes. We find that the empirical distribution trends toward uniformity as opposed to a Poisson Process. In systems in which consumer arrivals occur relatively infrequently, thus reducing emphasis on spillover, the wait times fall in the range of [0, busDistanceInterval]. Conversely, the trial that incorporated more waiting passengers into a system of increasingly spread out buses found the distribution frequencies spanned nearly twice the original COTA experiment. Hence, the resultant accumulation of wait times is impacted by spillover, while the distribution remains constant. This suggests that as long as bus route intervals remain consistent, the distribution of passenger wait times will be relatively uniform in nature.</p>
<p>Future research should take a look at a few variations of this project. This includes the distribution of buses along their respective routes, as well as the arrival rates of buses. Regarding bus allocation, this experiment commenced with one bus being dispersed at a time, until all buses were traversing routes. As a consequence, passengers arriving at the outermost routes see a spike in initial wait times. For example, assuming our parameters are in place, let Consumer A arrive at stop 4 at time t = 4 minutes. The first bus does not reach stop 4 until 80 minutes have elapsed, meaning Consumer A is forced to wait at least 76 minutes before boarding a bus. This may or may not be a desired scenario, depending on the bus system and city in consideration. Initially sending certain buses to later stops would more effectively distribute resources and service all bus stops equally during the first revolution. Alternatively, a bus system could simply direct potential passengers to wait until a certain operating time before waiting in line. The opening times of
bus stops would then vary by the bus distance interval. Secondly, in order to more accurately replicate a Poisson Process, it may be prudent to provide randomness between bus arrival times. This would allow for more variation between waiting times and could potentially lead to a more centralized distribution. The randomized arrival times must be limited somewhat by the fact that bus systems are predicated on strict scheduling. However, exact arrival times do not occur, so a bus arriving several minutes early or late still provides meaningful data both theoretically and practically.</p>    
<hr />
<h3>References</h3>
<ol start="0">
<li id="fn0">J. Dattorro. Convex Optimization and Euclidean Distance Geometry. <em>Meboo Publishing</em>, Stanford University, 2005.</li>
<li id="fn1">J. Reeb and S. Leavengood. Using the Graphical Method to Solve Linear Programs. <em>Performance Excellence in the Wood Products Industry: Operations Research</em>, Oregon State University, 1998.</li>
<li id="fn2">B. Sendov and H. Sendov. Duality between loci of complex polynomials and the zeros of polar derivatives. Math. Proc. Camb. Phil. Soc., 167, 6587, 2019.</li>
<li id="fn3">T. Tkocz. An introduction to convex and discrete geometry. Math 21-366 notes, <em>Carnegie Mellon University</em>, Fall 2019.</li>
<li id="fn4">J. Zwarts and P. Gardenfors. Locative and directional prepositions in conceptual spaces: The role of polar convexity. <em>J. Logic Language Information</em>. 2016.</li>
</ol>
  </body>
</html>
